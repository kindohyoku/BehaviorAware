# Behavior-Aware Anthropometric Scene Generation

This repository contains the project website for our CHI 2026 paper:

**Behavior-Aware Anthropometric Scene Generation for Human-Usable 3D Layouts**

Semin Jin*, Donghyuk Kim*, Jeongmin Ryu, Kyung Hoon Hyun†  
*Co-first authors, †Corresponding author

Design Informatics Lab, Hanyang University  
Human-Centered AI Design Institute, Hanyang University

## Abstract

Well-designed indoor scenes should prioritize how people can act within a space rather than merely what objects to place. However, existing 3D scene generation methods emphasize visual and semantic plausibility, while insufficiently addressing whether people can comfortably walk, sit, or manipulate objects. To bridge this gap, we present a Behavior-Aware Anthropometric Scene Generation framework. Our approach leverages vision–language models (VLMs) to analyze object–behavior relationships, translating spatial requirements into parametric layout constraints adapted to user-specific anthropometric data.

## Project Website

Visit our project website at: https://kindohyoku.github.io/BehaviorAware/

## Citation

```bibtex
@inproceedings{jin2026behavioraware,
  author    = {Jin, Semin and Kim, Donghyuk and Ryu, Jeongmin and Hyun, Kyung Hoon},
  title     = {Behavior-Aware Anthropometric Scene Generation for Human-Usable 3D Layouts},
  booktitle = {Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems},
  year      = {2026},
  pages     = {1--20},
  doi       = {10.1145/3772318.3790341}
}
```

## License

This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.
